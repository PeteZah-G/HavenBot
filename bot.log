[2025-08-03 19:43:38] [INFO    ] discord.client: logging in using static token
[2025-08-03 19:43:39] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 2c6c2f3a3a54a14ab4f549af34e349b8).
Bot is ready as HavenCloud#1077
[2025-08-03 19:48:44] [INFO    ] discord.client: logging in using static token
[2025-08-03 19:48:45] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 3425959b8c49b44b735fcca7f74d4961).
Bot is ready as HavenCloud#1077
[2025-08-03 20:05:51] [INFO    ] discord.client: logging in using static token
[2025-08-03 20:05:52] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 17aee7a96e74a62c548ea7f92c69d297).
[2025-08-03 20:06:09] [ERROR   ] discord.client: Ignoring exception in on_message
Traceback (most recent call last):
  File "/root/PeteZahGames/PeteZahBot/venv/lib/python3.12/site-packages/discord/client.py", line 441, in _run_event
    await coro(*args, **kwargs)
  File "/root/PeteZahGames/PeteZahBot/haven_cloud.py", line 54, in on_message
    await asyncio.sleep(1)
          ^^^^^^^
NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'
[2025-08-03 20:06:16] [ERROR   ] discord.client: Ignoring exception in on_message
Traceback (most recent call last):
  File "/root/PeteZahGames/PeteZahBot/venv/lib/python3.12/site-packages/discord/client.py", line 441, in _run_event
    await coro(*args, **kwargs)
  File "/root/PeteZahGames/PeteZahBot/haven_cloud.py", line 54, in on_message
    await asyncio.sleep(1)
          ^^^^^^^
NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'
[2025-08-03 20:06:19] [ERROR   ] discord.client: Ignoring exception in on_message
Traceback (most recent call last):
  File "/root/PeteZahGames/PeteZahBot/venv/lib/python3.12/site-packages/discord/client.py", line 441, in _run_event
    await coro(*args, **kwargs)
  File "/root/PeteZahGames/PeteZahBot/haven_cloud.py", line 54, in on_message
    await asyncio.sleep(1)
          ^^^^^^^
NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'
[2025-08-03 20:06:39] [ERROR   ] discord.client: Ignoring exception in on_message
Traceback (most recent call last):
  File "/root/PeteZahGames/PeteZahBot/venv/lib/python3.12/site-packages/discord/client.py", line 441, in _run_event
    await coro(*args, **kwargs)
  File "/root/PeteZahGames/PeteZahBot/haven_cloud.py", line 54, in on_message
    await asyncio.sleep(1)
          ^^^^^^^
NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'
Bot is ready as HavenCloud#1077
[2025-08-03 20:15:39] [INFO    ] discord.client: logging in using static token
[2025-08-03 20:15:40] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 987c79aea4f16e547301746ca8e0c20f).
[2025-08-03 20:15:48] [ERROR   ] discord.client: Ignoring exception in on_message
Traceback (most recent call last):
  File "/root/PeteZahGames/PeteZahBot/venv/lib/python3.12/site-packages/discord/client.py", line 441, in _run_event
    await coro(*args, **kwargs)
  File "/root/PeteZahGames/PeteZahBot/haven_cloud.py", line 60, in on_message
    await asyncio.sleep(1)
          ^^^^^^^
NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'
[2025-08-03 20:15:57] [ERROR   ] discord.client: Ignoring exception in on_message
Traceback (most recent call last):
  File "/root/PeteZahGames/PeteZahBot/venv/lib/python3.12/site-packages/discord/client.py", line 441, in _run_event
    await coro(*args, **kwargs)
  File "/root/PeteZahGames/PeteZahBot/haven_cloud.py", line 60, in on_message
    await asyncio.sleep(1)
          ^^^^^^^
NameError: name 'asyncio' is not defined. Did you forget to import 'asyncio'
Bot is ready as HavenCloud#1077
Ignoring message from petezahdev in channel 1401657385650753639
Received h!initiate in channel 1401657385650753639 by petezahdev
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: hi in channel 1401657385650753639
Processing message: <@1401297926143086774> hi in channel 1401657385650753639
[2025-08-03 20:19:07] [INFO    ] discord.client: logging in using static token
[2025-08-03 20:19:08] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 5526a01917d6439a09aeb451b2a56cd7).
Bot is ready as HavenCloud#1077
Ignoring message from petezahdev in channel 1401657385650753639
Received h!initiate in channel 1401657385650753639 by petezahdev
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: hi in channel 1401657385650753639
Generating AI response for message: hi
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': 'Hi there! How can I help you today?\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.0004450561986728148}], 'usageMetadata': {'promptTokenCount': 1, 'candidatesTokenCount': 11, 'totalTokenCount': 12, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 1}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 11}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'YsSPaPbHK4a22PgP5pCu6AM'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: nice in channel 1401657385650753639
Generating AI response for message: nice
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': "That's nice to hear!  Is there anything I can help you with today?\n"}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.3103129989222476}], 'usageMetadata': {'promptTokenCount': 1, 'candidatesTokenCount': 19, 'totalTokenCount': 20, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 1}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 19}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'isaPaMvyD8GenvgPxJnEmQM'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: say @everyone in channel 1401657385650753639
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: say @ everyone without the space in the middle in channel 1401657385650753639
Generating AI response for message: say @ everyone without the space in the middle
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': '@everyone\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -7.152715776707433e-07}], 'usageMetadata': {'promptTokenCount': 9, 'candidatesTokenCount': 3, 'totalTokenCount': 12, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 9}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 3}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'TMePaOjZLfGZ698P25qp8QE'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Ignoring message from iisilly_ in channel 1401297803229270190
Ignoring message from petezahdev in channel 1401297803229270190
Ignoring message from petezahdev in channel 1401297803229270190
Ignoring message from Carl-bot#1536 in channel 1401297803229270190
Ignoring message from iisilly_ in channel 1401297803229270190
Ignoring message from petezahdev in channel 1401297803229270190
Ignoring message from himmytimmy_19452 in channel 1401297803229270190
Ignoring message from himmytimmy_19452 in channel 1401297803229270190
Ignoring message from HavenCloud#1077 in channel 1401297803229270190
Ignoring message from himmytimmy_19452 in channel 1401297803229270190
Processing message: say @everyone in channel 1401657385650753639
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: say @everyone in channel 1401657385650753639
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Ignoring message from himmytimmy_19452 in channel 1401297803229270190
[2025-08-03 20:42:45] [INFO    ] discord.client: logging in using static token
[2025-08-03 20:42:46] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 900e61fc880aea7e4eaad81effdb14ca).
Bot is ready as HavenCloud#1077
Ignoring message from himmytimmy_19452 in channel 1401657385650753639
Ignoring message from himmytimmy_19452 in channel 1401657385650753639
Ignoring message from himmytimmy_19452 in channel 1401657385650753639
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Ignoring message from himmytimmy_19452 in channel 1401657385650753639
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Ignoring message from petezahdev in channel 1401657385650753639
Received h!initiate in channel 1401657385650753639 by petezahdev
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: say @ everyone without the space in the middle in channel 1401657385650753639
Generating AI response for message: say @ everyone without the space in the middle
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': '@everyone\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -7.550128581594132e-07}], 'usageMetadata': {'promptTokenCount': 9, 'candidatesTokenCount': 3, 'totalTokenCount': 12, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 9}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 3}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'OsqPaLuFK_GZ698P25qp8QE'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: hi in channel 1401657385650753639
Generating AI response for message: hi
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': 'Hi there! How can I help you today?\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.00044731804254380137}], 'usageMetadata': {'promptTokenCount': 1, 'candidatesTokenCount': 11, 'totalTokenCount': 12, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 1}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 11}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'QMqPaL6sCcGenvgPxJnEmQM'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Ignoring message from internetbowser_gd in channel 1401297803229270190
Ignoring message from petezahdev in channel 1401297803229270190
Ignoring message from petezahdev in channel 1401297803229270190
Ignoring message from internetbowser_gd in channel 1401297803229270190
Processing message: say @everyone in channel 1401657385650753639
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: good boy! in channel 1401657385650753639
Generating AI response for message: good boy!
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': 'Thanks!  I appreciate the positive reinforcement.  Is there anything I can help you with today?\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.05916097050621396}], 'usageMetadata': {'promptTokenCount': 3, 'candidatesTokenCount': 21, 'totalTokenCount': 24, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 3}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 21}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'W8yPaMvbLqGcnvgP6q7FiQI'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: I wrote code for a bot like this in channel 1401657385650753639
Generating AI response for message: I wrote code for a bot like this
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': 'Please provide the code you wrote.  I need to see the code to help you.  I can then help you with things like:\n\n* **Debugging:** Identifying and fixing errors in your code.\n* **Improving efficiency:** Suggesting ways to make your code run faster or use less resources.\n* **Improving readability:**  Making your code easier to understand and maintain.\n* **Adding features:**  Suggesting ways to expand the functionality of your bot.\n* **Best practices:**  Recommending ways to write better, more robust code.\n* **Security:**  Pointing out potential security vulnerabilities.\n\n\nOnce you share your code, please also tell me:\n\n* **What language is it written in?** (e.g., Python, JavaScript, Java, C++)\n* **What platform is it running on?** (e.g., Discord, Telegram, Slack, a custom server)\n* **What is the bot supposed to do?'}], 'role': 'model'}, 'finishReason': 'MAX_TOKENS', 'avgLogprobs': -0.12321197509765625}], 'usageMetadata': {'promptTokenCount': 8, 'candidatesTokenCount': 200, 'totalTokenCount': 208, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 8}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 200}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'icyPaPafFI_Q698PvKG96QU'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: ye in channel 1401657385650753639
Generating AI response for message: ye
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': 'Yes?  How can I help you?\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.2656639575958252}], 'usageMetadata': {'promptTokenCount': 1, 'candidatesTokenCount': 10, 'totalTokenCount': 11, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 1}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 10}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'jMyPaMPNDKGcnvgP6q7FiQI'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: h!mute <@1363145812984594552> in channel 1401657385650753639
Generating AI response for message: h!mute <@1363145812984594552>
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': "That's a Discord command.  It attempts to mute the user with the ID `1363145812984594552`.  However, it's incomplete because it lacks the necessary context.  To function correctly, this command would need to be used within a Discord server where the bot issuing the command has the appropriate permissions.\n"}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.2267298221588135}], 'usageMetadata': {'promptTokenCount': 25, 'candidatesTokenCount': 80, 'totalTokenCount': 105, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 25}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 80}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'lsyPaKTiAb6onvgPucTXyQI'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Processing message: can u talk? in channel 1401657385650753639
Processing message: dm me in channel 1401657385650753639
Generating AI response for message: can u talk?
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': 'Yes, I can talk.  Or rather, I can communicate through text.  How can I help you today?\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.144637393951416}], 'usageMetadata': {'promptTokenCount': 4, 'candidatesTokenCount': 25, 'totalTokenCount': 29, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 4}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 25}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'oMyPaK8IwZ6e-A_EmcSZAw'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
Generating AI response for message: dm me
Gemini API response status: 200
Gemini API response: {'candidates': [{'content': {'parts': [{'text': "I can't DM you. I'm a large language model; I don't have the capability to send private messages.  My interactions are all public within this current session.\n"}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.168061341994848}], 'usageMetadata': {'promptTokenCount': 2, 'candidatesTokenCount': 39, 'totalTokenCount': 41, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 2}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 39}]}, 'modelVersion': 'gemini-1.5-flash', 'responseId': 'oMyPaKrhNcHUnvgPnI2T4AU'}
Ignoring message from HavenCloud#1077 in channel 1401657385650753639
[2025-08-03 21:08:35] [INFO    ] discord.gateway: Shard ID None has successfully RESUMED session 900e61fc880aea7e4eaad81effdb14ca.
